<!doctype html>
<html lang="en" dir="ltr" class="plugin-pages plugin-id-default" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.9.2">
<title data-rh="true">Research | UltraRAG</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://ultrarag.github.io/website/img/docusaurus-social-card.jpg"><meta data-rh="true" name="twitter:image" content="https://ultrarag.github.io/website/img/docusaurus-social-card.jpg"><meta data-rh="true" property="og:url" content="https://ultrarag.github.io/website/research"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docusaurus_tag" content="default"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docsearch:docusaurus_tag" content="default"><meta data-rh="true" property="og:title" content="Research | UltraRAG"><meta data-rh="true" name="description" content="UltraRAG Research - Models and Papers"><meta data-rh="true" property="og:description" content="UltraRAG Research - Models and Papers"><link data-rh="true" rel="icon" href="/website/img/logo.svg"><link data-rh="true" rel="canonical" href="https://ultrarag.github.io/website/research"><link data-rh="true" rel="alternate" href="https://ultrarag.github.io/website/research" hreflang="en"><link data-rh="true" rel="alternate" href="https://ultrarag.github.io/website/research" hreflang="x-default"><link rel="alternate" type="application/rss+xml" href="/website/blog/rss.xml" title="UltraRAG RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/website/blog/atom.xml" title="UltraRAG Atom Feed"><link rel="stylesheet" href="/website/assets/css/styles.5d588865.css">
<script src="/website/assets/js/runtime~main.aa6eeb84.js" defer="defer"></script>
<script src="/website/assets/js/main.0b3925f5.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<svg style="display: none;"><defs>
<symbol id="theme-svg-external-link" viewBox="0 0 24 24"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></symbol>
</defs></svg>
<script>document.documentElement.setAttribute("data-theme","light"),document.documentElement.setAttribute("data-theme-choice","light"),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><link rel="preload" as="image" href="/website/img/_UltraRAG_logo.png"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="theme-layout-navbar navbar navbar--fixed-top"><div class="navbar__inner"><div class="theme-layout-navbar-left navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/website/"><div class="navbar__logo"><img src="/website/img/_UltraRAG_logo.png" alt="UltraRAG Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/website/img/_UltraRAG_logo.png" alt="UltraRAG Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div></a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/website/">Home</a><div class="navbar__item megaMenuContainer_wtH9"><a class="navbar__link megaMenuTrigger_WfrV" href="/website/research">Research</a><div class="megaMenuDropdown_Gd7n"><div class="dropdownContent_kjhv"><div class="menuColumn_pPJS"><div class="columnTitle_O7QQ">Latest</div><ul class="menuList_YKg9"><li class="menuItem_7MPO"><a class="menuLink_SVdn" href="/website/blog">Blog</a></li></ul></div><div class="menuColumn_pPJS"><div class="columnTitle_O7QQ">Models</div><ul class="menuList_YKg9"><li class="menuItem_7MPO"><a href="https://huggingface.co/openbmb/AgentCPM-Report" target="_blank" rel="noopener noreferrer" class="menuLink_SVdn">AgentCPM-Report</a></li><li class="menuItem_7MPO"><a href="https://huggingface.co/openbmb/MiniCPM-Embedding-Light" target="_blank" rel="noopener noreferrer" class="menuLink_SVdn">MiniCPM-Embedding-Light</a></li></ul></div><div class="menuColumn_pPJS"><div class="columnTitle_O7QQ">Papers</div><ul class="menuList_YKg9"><li class="menuItem_7MPO"><a class="menuLink_SVdn" href="/website/research#papers">Featured Papers</a></li></ul></div></div></div></div><div class="navbar__item megaMenuContainer_wtH9"><a class="navbar__link megaMenuTrigger_WfrV" href="/website/team">Team</a><div class="megaMenuDropdown_Gd7n"><div class="dropdownContent_kjhv"><div class="menuColumn_pPJS"><div class="columnTitle_O7QQ">About</div><ul class="menuList_YKg9"><li class="menuItem_7MPO"><a class="menuLink_SVdn" href="/website/team">Members</a></li></ul></div><div class="menuColumn_pPJS"><div class="columnTitle_O7QQ">Connect</div><ul class="menuList_YKg9"><li class="menuItem_7MPO"><a class="menuLink_SVdn" href="/website/contact">Contact</a></li><li class="menuItem_7MPO"><a href="https://nlp.csai.tsinghua.edu.cn/job/29" target="_blank" rel="noopener noreferrer" class="menuLink_SVdn">Join Us</a></li></ul></div></div></div></div></div><div class="theme-layout-navbar-right navbar__items navbar__items--right"><div class="navbar__item"><a href="https://github.com/OpenBMB/UltraRAG" target="_blank" rel="noopener noreferrer" class="githubButton_sUw0" aria-label="Star OpenBMB/UltraRAG on GitHub"><div class="iconWrapper_DaS4"><svg height="24" width="24" viewBox="0 0 16 16" version="1.1" fill="currentColor" style="flex-shrink:0"><path fill-rule="evenodd" d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.013 8.013 0 0016 8c0-4.42-3.58-8-8-8z"></path></svg></div><div class="starText_BhhA">...</div></a></div><div class="switcher_Z8Ac"><button class="btn_xjeh active_YUPQ">EN</button><span class="divider_TN9w">|</span><button class="btn_xjeh">中文</button></div><div class="navbarSearchContainer_Bca1"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="theme-layout-main main-wrapper mainWrapper_z2l0"><main><section class="heroSection_Z9Mr"><div class="heroContent_qtjE"><h1 class="heroTitle_vU1X">Research</h1><p class="heroSubtitle_kRhI">Discover our latest research</p></div></section><section id="blog" class="blogSection_lCNf"><div class="container_WYko"><div class="sectionHeaderRow_W0pW"><div class="sectionHeader_Y0cu"><h2 class="sectionTitle_SiJ3">Blog</h2><p class="sectionDesc_akIc">Follow UltraRAG open-source progress and technical updates.</p></div><a class="viewAllLink_Fu35" href="/website/blog">View All<!-- --> <span>→</span></a></div><a class="blogFeatured_KVNL" href="/website/blog/ultrarag-3.0-release"><div class="blogFeaturedTag_ASbk">Release</div><h3 class="blogFeaturedTitle_ANJ8">UltraRAG 3.0: No More Black Boxes, Full Transparency in Reasoning</h3><p class="blogFeaturedSummary_jf4A">Addressing the pain point of &quot;algorithm prototyping takes a week, but building a usable system takes months&quot;, UltraRAG 3.0 brings three core upgrades: full-chain visible reasoning, modular MCP architecture, and unified evaluation system.</p><div class="blogFeaturedMeta_IwN9"><span>2026.01.23</span><span class="blogMetaDivider_FxyP">·</span><span>Sen Mei, Haidong Xin</span></div></a><div class="blogGrid_fbaM"><a class="blogCard_azRs" href="/website/blog/ultrarag-2.1-release"><div class="blogCardTag_GYkW">Release</div><h3 class="blogCardTitle_ZsqN">UltraRAG 2.1: Deep Knowledge Integration, Cross-Modal Support</h3><p class="blogCardSummary_Y5af">Comprehensive upgrades focused on native multimodal support, automated knowledge integration and corpus construction, and unified RAG workflows for building and evaluation.</p><div class="blogCardMeta_Mbwr"><span>2025.11.11</span><span class="blogMetaDivider_FxyP">·</span><span>Sen Mei, Haidong Xin</span></div></a><a class="blogCard_azRs" href="/website/blog/ultrarag-2.0-release"><div class="blogCardTag_GYkW">Release</div><h3 class="blogCardTitle_ZsqN">UltraRAG 2.0: Minimal Code, Maximum Innovation</h3><p class="blogCardSummary_Y5af">The first RAG framework designed with Model Context Protocol (MCP) architecture, enabling researchers to implement multi-stage reasoning systems with just YAML files.</p><div class="blogCardMeta_Mbwr"><span>2025.08.28</span><span class="blogMetaDivider_FxyP">·</span><span>Sen Mei, Haidong Xin, Chunyi Peng</span></div></a></div></div></section><section class="modelsSection_NIqE"><div class="container_WYko"><div class="sectionHeader_Y0cu"><h2 class="sectionTitle_SiJ3">Models</h2><p class="sectionDesc_akIc">Our open-source core models, providing foundational capabilities for the RAG ecosystem.</p></div><div class="modelsGrid_fS_7"><a href="https://huggingface.co/openbmb/AgentCPM-Report" target="_blank" rel="noopener noreferrer" class="modelCard_P1Gx"><div class="modelCardInner_vg_f"><h3 class="modelName_bhxY">AgentCPM-Report</h3><p class="modelDesc_coF9">An intelligent Agent model for long document generation and report writing, enabling automated research report generation.</p><div class="modelTags_ZuK8"><span class="modelTag_aW0T">Agent</span><span class="modelTag_aW0T">Long-Text Generation</span><span class="modelTag_aW0T">DeepResearch</span></div><div class="modelLink_Zx0Q">View Model<!-- --> <span class="modelArrow_Li7v">→</span></div></div></a><a href="https://huggingface.co/openbmb/MiniCPM-Embedding-Light" target="_blank" rel="noopener noreferrer" class="modelCard_P1Gx"><div class="modelCardInner_vg_f"><h3 class="modelName_bhxY">MiniCPM-Embedding-Light</h3><p class="modelDesc_coF9">A lightweight and efficient text embedding model, achieving leading performance on multiple retrieval benchmarks, suitable for large-scale semantic retrieval in RAG scenarios.</p><div class="modelTags_ZuK8"><span class="modelTag_aW0T">Embedding</span><span class="modelTag_aW0T">Retrieval</span></div><div class="modelLink_Zx0Q">View Model<!-- --> <span class="modelArrow_Li7v">→</span></div></div></a></div></div></section><section id="papers" class="papersSection_BzfN"><div class="container_WYko"><div class="sectionHeader_Y0cu"><h2 class="sectionTitle_SiJ3">Featured Papers</h2><p class="sectionDesc_akIc">Representative research work from our team in the RAG domain.</p></div><div class="papersList_fyoz"><a href="https://arxiv.org/pdf/2410.10594" target="_blank" rel="noopener noreferrer" class="paperCard_xbJw"><div class="paperMeta_ylCd"><span class="paperDate_s3j4">2025.04</span><span class="paperVenue_bswl">ICLR 2025</span></div><h3 class="paperTitle_MgHI">VisRAG: Vision-based Retrieval-Augmented Generation on Multi-modality Documents</h3><p class="paperAuthors_kCxq">Shi Yu, Chaoyue Tang, et al.</p><p class="paperAbstract_u2On">Proposes a &quot;vision-first&quot; retrieval-augmented generation paradigm that fundamentally solves the information degradation problem of complex layout documents in traditional text parsing by converting documents directly into visual vectors for matching and generation.</p><div class="paperLinkText_yiu8">Read More<!-- --> <span class="paperArrow_Xwda">→</span></div></a><a href="https://arxiv.org/pdf/2410.13509" target="_blank" rel="noopener noreferrer" class="paperCard_xbJw"><div class="paperMeta_ylCd"><span class="paperDate_s3j4">2025.04</span><span class="paperVenue_bswl">ICLR 2025</span></div><h3 class="paperTitle_MgHI">RAG-DDR: Optimizing Retrieval-Augmented Generation Using Differentiable Data Rewards</h3><p class="paperAuthors_kCxq">Xinze Li, Sen Mei, et al.</p><p class="paperAbstract_u2On">Proposes a new RAG optimization paradigm based on &quot;differentiable data rewards&quot;, significantly improving the model&#x27;s ability to extract core information from external knowledge and resolve knowledge conflicts through end-to-end reward alignment between retriever and generator.</p><div class="paperLinkText_yiu8">Read More<!-- --> <span class="paperArrow_Xwda">→</span></div></a><a href="https://aclanthology.org/2025.acl-long.418.pdf" target="_blank" rel="noopener noreferrer" class="paperCard_xbJw"><div class="paperMeta_ylCd"><span class="paperDate_s3j4">2025.07</span><span class="paperVenue_bswl">ACL 2025</span></div><h3 class="paperTitle_MgHI">RAGEval: Scenario Specific RAG Evaluation Dataset Generation Framework</h3><p class="paperAuthors_kCxq">Kunlun Zhu, Yifan Luo, et al.</p><p class="paperAbstract_u2On">Proposes a new paradigm for automated RAG evaluation benchmark construction, enabling efficient customization of evaluation datasets for specific vertical scenarios (such as finance, law, healthcare) through Schema-based knowledge distillation and document generation.</p><div class="paperLinkText_yiu8">Read More<!-- --> <span class="paperArrow_Xwda">→</span></div></a><a href="https://arxiv.org/pdf/2410.08821" target="_blank" rel="noopener noreferrer" class="paperCard_xbJw"><div class="paperMeta_ylCd"><span class="paperDate_s3j4">2025.11</span><span class="paperVenue_bswl">EMNLP 2025</span></div><h3 class="paperTitle_MgHI">DeepNote: Note-Centric Deep Retrieval-Augmented Generation</h3><p class="paperAuthors_kCxq">Ruobing Wang, et al.</p><p class="paperAbstract_u2On">Proposes a &quot;note-centric&quot; adaptive retrieval-augmented generation paradigm that significantly improves the model&#x27;s depth and robustness in handling complex open-domain QA tasks by introducing an iterative knowledge accumulation mechanism.</p><div class="paperLinkText_yiu8">Read More<!-- --> <span class="paperArrow_Xwda">→</span></div></a></div></div></section></main></div><footer class="theme-layout-footer footer"><div class="container container-fluid"><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2026 UltraRAG.</div></div></div></footer></div>
</body>
</html>